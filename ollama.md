# ollama
> 로컬에서 LLM 실행

```sh
brew install ollama
```

## model 생성
+ https://github.com/ollama/ollama/blob/main/docs/modelfile.md

### 예제
+ https://huggingface.co/MLP-KTLim/llama-3-Korean-Bllossom-8B-gguf-Q4_K_M/discussions/1#664328f8094be67723ba44ad

## 에러
### llama-3-Korean-Bllossom-8B-gguf-Q4_K_M
- [[diary:2024-05-23]]
- 토큰이 세는 듯한 이상동작
+ https://huggingface.co/MLP-KTLim/llama-3-Korean-Bllossom-8B-gguf-Q4_K_M/discussions/1#664328f8094be67723ba44ad
```
# blah blah blah 
{||imStart|}질문{ |imEnd| }
# blah blah blah 
```

## link
- [[llama]]
- [[huggingface]]
